spark - Sequence file and accumulators

RDD persistence: you can use your disk for storage incase you run out of memory while processing data. 

1. import org.apache.spark.storage.StorageLevel
2. products.persist(StorageLevel.Memory_AND_DISK)
3. producsts.unpersist --- to unpersist

* Sequence file:

Study Sequence file again

------------------------------------------------------

Accumulator - used to count
eg. count how many times the paticular function has been invoked

Broadcast variable:
- they are variables we share through out the clusters. But the variable have to be able to fit in the memory
on ONE machine
- they are immutable. Cannot be changed later on.
- reduces the number of shuffling while joining huge tables

