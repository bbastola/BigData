Problem 4

Import orders table from mysql as text file to the destination /user/cloudera/problem5/text. Fields should be terminated by a tab character ("\t") character and lines should be terminated by new line character ("\n"). 

sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/problem5/text \
--as-textfile \
--fields-terminated-by "\t" \
--lines-terminated-by "\n"

Import orders table from mysql  into hdfs to the destination /user/cloudera/problem5/avro. File should be stored as avro file.

sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/problem5/avro \
--as-avrodatafile 

Import orders table from mysql  into hdfs  to folders /user/cloudera/problem5/parquet. File should be stored as parquet file.

sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/problem5/parquet \
--as-parquetfile

Transform/Convert data-files at /user/cloudera/problem5/avro and store the converted file at the following locations and file formats

save the data to hdfs using snappy compression as parquet file at /user/cloudera/problem5/parquet-snappy-compress

avroData = sqlContext.read.format("com.databricks.spark.avro").load("/user/cloudera/problem5/avro")
sqlContext.setConf("spark.sql.parquet.compression.codec", "Snappy")

save the data to hdfs using gzip compression as text file at /user/cloudera/problem5/text-gzip-compress

avroData.map(lambda r: (str(r[0])+","+str(r[1])+","+str(r[2])+","+r[3])).saveAsTextFile("/user/cloudera/problem5/text-gzip-compress","org.apache.hadoop.io.compress.GzipCodec")

save the data to hdfs using no compression as sequence file at /user/cloudera/problem5/sequence

avroData.map(lambda r: (str(r[0])+","+str(r[1])+","+str(r[2])+","+r[3])).saveAsSequenceFile("/user/cloudera/problem5/sequence")

save the data to hdfs using snappy compression as text file at /user/cloudera/problem5/text-snappy-compress

avroData.map(lambda r: (str(r[0])+","+str(r[1])+","+str(r[2])+","+r[3])).saveAsTextFile("/user/cloudera/problem5/text-snappy-compress","org.apache.hadoop.io.compress.SnappyCodec")
