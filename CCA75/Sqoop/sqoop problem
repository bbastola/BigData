Problem:

//Create HDFS directory with name retail_data
hadoop fs -mkdir /user/bbastola/retail_data

//Import all tables using avro file format, compression and number of mappers as 2
sqoop import-all-tables \
--connect jdbc:mysql://ms.itversity.com/retail_db \
--username retail_user \
--password itversity \
--warehouse-dir /user/bbastola/retail_data \
--as-avrodatafile \
--compress \
--compression-codec "org.apache.hadoop.io.compress.SnappyCodec" \
--num-mappers 2

Import orders table to hive database of yours (text file) - Using sqoop import with --hive-import and delimiter ‘|’ - use table name orders_sqooped

sqoop import \
--connect jdbc:mysql://ms.itversity.com/retail_db \
--username retail_user \
--password itversity \
--table orders \
--hive-database bbastola_retail \
--fields-terminated-by "|" \
--hive-table order_sqooped



